{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_nn",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3CnztKolUWR",
        "colab_type": "code",
        "outputId": "2b96f10b-7f0f-4826-9976-0353e63a7bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0uF2HIdOhZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import argparse\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rpqfXsvOq56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Net(object):\n",
        "    def __init__(self, layers):\n",
        "        self.dims = layers[0]\n",
        "        self.activations = layers[1]\n",
        "        self.params = {}\n",
        "        self.L = len(self.dims)\n",
        "        self.n = 0\n",
        "        self.losses = []\n",
        "        self.cache = {}\n",
        "\n",
        "\n",
        "    def init_params(self):\n",
        "        np.random.seed(1)\n",
        "\n",
        "        for l in range(0, len(self.dims) - 1):\n",
        "            self.params[\"W\" + str(l+1)] = np.random.randn(self.dims[l+1], self.dims[l]) / np.sqrt(\n",
        "                self.dims[l])\n",
        "            self.params[\"b\" + str(l+1)] = np.zeros((self.dims[l+1], 1))\n",
        "\n",
        "\n",
        "    def relu(self, Z):\n",
        "        return np.maximum(0,Z)\n",
        "\n",
        "\n",
        "    def sigmoid(self, Z):\n",
        "        return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "\n",
        "    def softmax(self, Z):\n",
        "        expZ = np.exp(Z - np.max(Z))\n",
        "        return expZ / expZ.sum(axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "    def activation(self, Z, activations):\n",
        "        if activations == 'sigmoid':\n",
        "            A = self.sigmoid(Z)\n",
        "        elif activations == 'relu':\n",
        "            A = self.relu(Z)\n",
        "        elif activations == 'softmax':\n",
        "            A = self.softmax(Z)\n",
        "        return A\n",
        "\n",
        "    def forward(self, X):\n",
        "        # cache = {}\n",
        "\n",
        "        A = X.T\n",
        "\n",
        "        for l in range(self.L - 1):\n",
        "            Z = self.params[\"W\" + str(l + 1)].dot(A) + self.params[\"b\" + str(l + 1)]\n",
        "            A = self.activation(Z, self.activations[l])\n",
        "\n",
        "            self.cache[\"A\" + str(l + 1)] = A\n",
        "            self.cache[\"W\" + str(l + 1)] = self.params[\"W\" + str(l + 1)]\n",
        "            self.cache[\"Z\" + str(l + 1)] = Z\n",
        "\n",
        "        Z = self.params[\"W\" + str(self.L)].dot(A) + self.params[\"b\" + str(self.L)]\n",
        "        A = self.activation(Z, self.activations[self.L - 1])\n",
        "\n",
        "        self.cache[\"A\" + str(self.L)] = A\n",
        "        self.cache[\"W\" + str(self.L)] = self.params[\"W\" + str(self.L)]\n",
        "        self.cache[\"Z\" + str(self.L)] = Z\n",
        "\n",
        "        return A\n",
        "\n",
        "\n",
        "    def sigmoid_derivative(self, Z):\n",
        "        s = 1 / (1 + np.exp(-Z))\n",
        "        return s * (1 - s)\n",
        "\n",
        "\n",
        "    def relu_derivative(self, Z):\n",
        "        Z[Z<=0] = 0\n",
        "        Z[Z>0] = 1\n",
        "        return Z\n",
        "\n",
        "\n",
        "    def activation_derivative(self, Z, activations):\n",
        "        if activations == 'sigmoid':\n",
        "            dZ = self.sigmoid_derivative(Z)\n",
        "        elif activations == 'relu':\n",
        "            dZ = self.relu_derivative(Z)\n",
        "        elif activations == 'softmax':\n",
        "            dZ = 1\n",
        "        return dZ\n",
        "\n",
        "\n",
        "    def compute_loss(self, y, y_hat):\n",
        "        return  -np.sum(y*np.log(y_hat.T))/self.n\n",
        "\n",
        "\n",
        "    def backward(self, X, Y):\n",
        "        derivatives = {}\n",
        "        self.cache[\"A0\"] = X.T\n",
        "\n",
        "        A = self.cache[\"A\" + str(self.L)]\n",
        "        dZ = (A - Y.T)*(self.activation_derivative(self.cache[\"Z\" + str(self.L)], self.activations[self.L - 1])) / self.n\n",
        "\n",
        "        dW = dZ.dot(self.cache[\"A\" + str(self.L - 1)].T)\n",
        "        db = np.sum(dZ, axis=1, keepdims=True)\n",
        "        dA_prev = self.cache[\"W\" + str(self.L)].T.dot(dZ) \n",
        "\n",
        "        derivatives[\"dW\" + str(self.L)] = dW\n",
        "        derivatives[\"db\" + str(self.L)] = db\n",
        "\n",
        "        for l in range(self.L - 1, 0, -1):\n",
        "            dZ = dA_prev * self.activation_derivative(self.cache[\"Z\" + str(l)], self.activations[ l - 1])\n",
        "            dW = dZ.dot(self.cache[\"A\" + str(l - 1)].T)\n",
        "            db = np.sum(dZ, axis=1, keepdims=True)\n",
        "            if l > 1:\n",
        "                dA_prev = self.cache[\"W\" + str(l)].T.dot(dZ)\n",
        "            derivatives[\"dW\" + str(l)] = dW\n",
        "            derivatives[\"db\" + str(l)] = db\n",
        "\n",
        "        return derivatives\n",
        "\n",
        "\n",
        "    def update_weight(self, derivatives, lr):\n",
        " \n",
        "        # update weight\n",
        "        for l in range(1, self.L + 1):\n",
        "            self.params[\"W\" + str(l)] = self.params[\"W\" + str(l)] - lr * derivatives[\n",
        "                \"dW\" + str(l)]\n",
        "            self.params[\"b\" + str(l)] = self.params[\"b\" + str(l)] - lr * derivatives[\n",
        "                \"db\" + str(l)]\n",
        "\n",
        "\n",
        "    def random_mini_batches(self,X,y,mini_batch_size):\n",
        "        m = X.shape[0]\n",
        "        mini_batches = []\n",
        "        permutation = list(np.random.permutation(m))\n",
        "        shuffled_X = X[permutation,:]\n",
        "        shuffled_Y = y[permutation,:]\n",
        "\n",
        "        # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "        num_complete_minibatches = math.floor(\n",
        "            m / mini_batch_size)  # number of mini batches of size mini_batch_size in your partitionning\n",
        " \n",
        "        for k in range(0, num_complete_minibatches):\n",
        "            mini_batch_X = shuffled_X[ k * mini_batch_size: (k + 1) * mini_batch_size,:]\n",
        "            mini_batch_Y = shuffled_Y[ k * mini_batch_size: (k + 1) * mini_batch_size,:]\n",
        "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "            mini_batches.append(mini_batch)\n",
        "\n",
        "        # Handling the end case (last mini-batch < mini_batch_size)\n",
        "        if m % mini_batch_size != 0:\n",
        "            mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size: m,:]\n",
        "            mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size: m,:]\n",
        "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "            mini_batches.append(mini_batch)\n",
        "\n",
        "        return mini_batches\n",
        "\n",
        "\n",
        "    def fit(self, X, Y, lr=0.01, epochs=20, batch_size=32):\n",
        "        np.random.seed(1)\n",
        "        self.n = batch_size\n",
        "        self.dims.insert(0, X.shape[1])\n",
        "        self.init_params()\n",
        "\n",
        "        for e in range(epochs):\n",
        "            mini_batches = self.random_mini_batches(X, Y, batch_size)\n",
        "\n",
        "            for mini_batch_X, mini_batch_Y in mini_batches:\n",
        "                A = self.forward(mini_batch_X)\n",
        "                loss = self.compute_loss(mini_batch_Y, A)\n",
        "                derivatives = self.backward(mini_batch_X, mini_batch_Y)\n",
        "                self.update_weight(derivatives, lr)\n",
        "\n",
        "            self.losses.append(loss)\n",
        "            # print(\"Epochs\",e + 1,\"/\", epochs, \" - loss:\", loss, \" - acc:\", self.evaluate(X, Y))\n",
        "            print(\"Epochs %d/%d - loss: %.5f - acc: %.5f\" % (e+1, epochs, loss, self.evaluate(X, Y)))\n",
        "\n",
        "    def predict(self, X):\n",
        "        A = self.forward(X)\n",
        "        y_hat = np.argmax(A, axis=0)\n",
        "        return y_hat\n",
        "\n",
        "\n",
        "    def evaluate(self, X, Y):\n",
        "        y_hat = self.predict(X)\n",
        "        Y = np.argmax(Y, axis=1)\n",
        "        accuracy = (y_hat == Y).mean()\n",
        "        return accuracy * 100\n",
        "\n",
        "\n",
        "    def plot_loss(self):\n",
        "        plt.figure()\n",
        "        plt.plot(np.arange(len(self.losses)), self.losses)\n",
        "        plt.xlabel(\"epochs\")\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB_b0PkHOt-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process_data(X_train, y_train, X_val, y_val, X_test):\n",
        "\n",
        "    enc = OneHotEncoder(sparse=False)\n",
        "    y_train = enc.fit_transform(y_train.reshape(len(y_train), -1))\n",
        "\n",
        "    y_val = enc.transform(y_val.reshape(len(y_val), -1))\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJUuiwNZOuoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "    df_train = pd.read_csv(path + 'train.csv')\n",
        "    df_test = pd.read_csv(path + 'test.csv')\n",
        "\n",
        "    df_features = df_train.iloc[:, 1:785]\n",
        "    df_label = df_train.iloc[:, 0]\n",
        "\n",
        "    X_test = df_test.iloc[:, 0:784]\n",
        "\n",
        "    X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label, \n",
        "                                                test_size = 0.2,\n",
        "                                                random_state = 1212)\n",
        "\n",
        "\n",
        "    X_train = np.array(X_train).reshape(33600, 784)\n",
        "    X_cv = np.array(X_cv).reshape(8400, 784)\n",
        "    X_test = np.array(X_test).reshape(28000, 784)\n",
        "    \n",
        "    # Feature Normalization \n",
        "    X_train = X_train.astype('float32'); X_cv= X_cv.astype('float32'); X_test = X_test.astype('float32')\n",
        "    X_train /= 255; X_cv /= 255; X_test /= 255\n",
        "    y_train = np.array(y_train)\n",
        "    y_cv = np.array(y_cv)\n",
        "    return X_train, y_train, X_cv, y_cv, X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXP2Hdw3ycL9",
        "colab_type": "code",
        "outputId": "5a79c38e-e5db-410d-d712-0037274b6ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "X_train, y_train, X_val, y_val, X_test = load_data('/content/drive/My Drive/digit-recognizer/')\n",
        "X_train, y_train, X_val, y_val, X_test = pre_process_data(X_train, y_train, X_val, y_val, X_test)\n",
        "print(\"X_train's shape: \" + str(X_train.shape))\n",
        "print(\"X_val's shape: \" + str(X_val.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train's shape: (33600, 784)\n",
            "X_val's shape: (8400, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t2dfUNGOwvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build neural network\n",
        "layers_dims = [1000, 10]\n",
        "act_fucntion = ['relu', 'softmax']\n",
        "layers = (layers_dims, act_fucntion)\n",
        "net = Neural_Net(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ6WZV4v3qL0",
        "colab_type": "code",
        "outputId": "0cd1da6f-f0a2-4d27-fc6b-492135bea9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "# Train network\n",
        "net.fit(X_train, y_train, lr = 0.1, epochs=50, batch_size=32)\n",
        "print(\"Train Accuracy: %.5f\" % net.evaluate(X_train, y_train))\n",
        "print(\"Test Accuracy: %.5f\" % net.evaluate(X_val, y_val))\n",
        "net.plot_loss()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs 1/50 - loss: 0.14733 - acc: 93.83036\n",
            "Epochs 2/50 - loss: 0.20904 - acc: 96.36310\n",
            "Epochs 3/50 - loss: 0.03464 - acc: 97.48512\n",
            "Epochs 4/50 - loss: 0.06322 - acc: 98.18750\n",
            "Epochs 5/50 - loss: 0.02483 - acc: 98.54167\n",
            "Epochs 6/50 - loss: 0.02772 - acc: 98.96131\n",
            "Epochs 7/50 - loss: 0.01347 - acc: 99.14286\n",
            "Epochs 8/50 - loss: 0.01462 - acc: 99.41667\n",
            "Epochs 9/50 - loss: 0.02324 - acc: 99.49405\n",
            "Epochs 10/50 - loss: 0.00571 - acc: 99.53571\n",
            "Epochs 11/50 - loss: 0.01660 - acc: 99.79167\n",
            "Epochs 12/50 - loss: 0.00925 - acc: 99.81845\n",
            "Epochs 13/50 - loss: 0.00890 - acc: 99.88393\n",
            "Epochs 14/50 - loss: 0.01139 - acc: 99.93452\n",
            "Epochs 15/50 - loss: 0.02911 - acc: 99.96131\n",
            "Epochs 16/50 - loss: 0.01101 - acc: 99.97917\n",
            "Epochs 17/50 - loss: 0.00355 - acc: 99.98512\n",
            "Epochs 18/50 - loss: 0.00575 - acc: 99.98810\n",
            "Epochs 19/50 - loss: 0.01149 - acc: 99.99107\n",
            "Epochs 20/50 - loss: 0.00511 - acc: 99.98810\n",
            "Epochs 21/50 - loss: 0.00487 - acc: 99.99107\n",
            "Epochs 22/50 - loss: 0.00487 - acc: 99.99405\n",
            "Epochs 23/50 - loss: 0.00507 - acc: 100.00000\n",
            "Epochs 24/50 - loss: 0.04398 - acc: 99.97321\n",
            "Epochs 25/50 - loss: 0.00246 - acc: 100.00000\n",
            "Epochs 26/50 - loss: 0.00073 - acc: 100.00000\n",
            "Epochs 27/50 - loss: 0.00192 - acc: 100.00000\n",
            "Epochs 28/50 - loss: 0.00045 - acc: 100.00000\n",
            "Epochs 29/50 - loss: 0.00133 - acc: 100.00000\n",
            "Epochs 30/50 - loss: 0.00015 - acc: 100.00000\n",
            "Epochs 31/50 - loss: 0.00033 - acc: 100.00000\n",
            "Epochs 32/50 - loss: 0.00226 - acc: 100.00000\n",
            "Epochs 33/50 - loss: 0.00099 - acc: 100.00000\n",
            "Epochs 34/50 - loss: 0.00187 - acc: 100.00000\n",
            "Epochs 35/50 - loss: 0.00442 - acc: 100.00000\n",
            "Epochs 36/50 - loss: 0.00089 - acc: 100.00000\n",
            "Epochs 37/50 - loss: 0.00566 - acc: 100.00000\n",
            "Epochs 38/50 - loss: 0.00232 - acc: 100.00000\n",
            "Epochs 39/50 - loss: 0.00190 - acc: 100.00000\n",
            "Epochs 40/50 - loss: 0.00095 - acc: 100.00000\n",
            "Epochs 41/50 - loss: 0.00272 - acc: 100.00000\n",
            "Epochs 42/50 - loss: 0.00285 - acc: 100.00000\n",
            "Epochs 43/50 - loss: 0.00301 - acc: 100.00000\n",
            "Epochs 44/50 - loss: 0.00017 - acc: 100.00000\n",
            "Epochs 45/50 - loss: 0.00006 - acc: 100.00000\n",
            "Epochs 46/50 - loss: 0.00239 - acc: 100.00000\n",
            "Epochs 47/50 - loss: 0.00228 - acc: 100.00000\n",
            "Epochs 48/50 - loss: 0.00202 - acc: 100.00000\n",
            "Epochs 49/50 - loss: 0.00092 - acc: 100.00000\n",
            "Epochs 50/50 - loss: 0.00066 - acc: 100.00000\n",
            "Train Accuracy: 100.00000\n",
            "Test Accuracy: 98.03571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkawUFiIiktX/Bxxr0ZBzJ1BOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19min 32s, sys: 12min 11s, total: 31min 43s\n",
            "Wall time: 8min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1C7prHytbfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict with test data\n",
        "y_hat = net.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2P9XMxlxsQj",
        "colab_type": "code",
        "outputId": "a18b3f7c-3c11-40ae-cffa-12f7f182921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "random_indexes = random.sample(range(X_test.shape[0]),5)\n",
        "#Visualizing the orginal images\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5)\n",
        "original_images = [X_test[i].reshape((28, 28)) for i in random_indexes]\n",
        "i = 0\n",
        "for ax in axes:\n",
        "    ax.imshow(original_images[i], cmap ='gist_gray')\n",
        "    i += 1\n",
        "fig.tight_layout()\n",
        "print(y_hat[random_indexes])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 1 8 3 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAABVCAYAAAAcyXCzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n10Lo7TsFYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'ImageId': np.arange(1, y_hat.shape[0]+ 1), 'Label': y_hat[:]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUK1I3YcsGvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_csv = df.to_csv (r'submission.csv', index = None, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8PefseAU3ok",
        "colab_type": "code",
        "outputId": "bd693b5b-4d82-4bb6-ef0c-10b517ccc937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "%%time\n",
        "!python mnist_ann.py --path '/content/drive/My Drive/digit-recognizer/' --lr=0.1 --epochs=20 --batch_size=32"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "X_train's shape: (33600, 784)\n",
            "X_val's shape: (8400, 784)\n",
            "Epochs 1/20 - loss: 0.14733 - acc: 93.83036\n",
            "Epochs 2/20 - loss: 0.20904 - acc: 96.36310\n",
            "Epochs 3/20 - loss: 0.03464 - acc: 97.48512\n",
            "Epochs 4/20 - loss: 0.06322 - acc: 98.18750\n",
            "Epochs 5/20 - loss: 0.02483 - acc: 98.54167\n",
            "Epochs 6/20 - loss: 0.02772 - acc: 98.96131\n",
            "Epochs 7/20 - loss: 0.01347 - acc: 99.14286\n",
            "Epochs 8/20 - loss: 0.01462 - acc: 99.41667\n",
            "Epochs 9/20 - loss: 0.02324 - acc: 99.49405\n",
            "Epochs 10/20 - loss: 0.00571 - acc: 99.53571\n",
            "Epochs 11/20 - loss: 0.01660 - acc: 99.79167\n",
            "Epochs 12/20 - loss: 0.00925 - acc: 99.81845\n",
            "Epochs 13/20 - loss: 0.00890 - acc: 99.88393\n",
            "Epochs 14/20 - loss: 0.01139 - acc: 99.93452\n",
            "Epochs 15/20 - loss: 0.02911 - acc: 99.96131\n",
            "Epochs 16/20 - loss: 0.01101 - acc: 99.97917\n",
            "Epochs 17/20 - loss: 0.00355 - acc: 99.98512\n",
            "Epochs 18/20 - loss: 0.00575 - acc: 99.98810\n",
            "Epochs 19/20 - loss: 0.01149 - acc: 99.99107\n",
            "Epochs 20/20 - loss: 0.00511 - acc: 99.98810\n",
            "Train Accuracy: 99.98809523809524\n",
            "Test Accuracy: 97.95238095238096\n",
            "CPU times: user 1.14 s, sys: 160 ms, total: 1.3 s\n",
            "Wall time: 3min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}